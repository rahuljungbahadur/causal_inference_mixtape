{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainee = pd.read_csv('trainees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   unit  trainees  age  earnings\n0     1         1   28     17700\n1     2         1   34     10200\n2     3         1   29     14400\n3     4         1   25     20800\n4     5         1   29      6100"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No control whatsoever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple diff in means of trained vs untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple diff in [trained - untrained] means = -4297.0\n"
     ]
    }
   ],
   "source": [
    "## A simple diff in means\r\n",
    "simple_diff = np.round(((trainee.query('trainees==1').earnings.mean()) - (trainee.query('trainees==0').earnings.mean())))\r\n",
    "print(f\"simple diff in [trained - untrained] means = {simple_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS based simple diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ols = smf.ols(\"earnings ~ trainees\", data = trainee).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Intercept    20723.809524\ntrainees     -4297.493734\ndtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_ols.params   ## Simople diff in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control for age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='age', ylabel='earnings'>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x = \"age\", y = \"earnings\", hue = \"trainees\", data = trainee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='age', ylabel='Density'>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(x = \"age\", hue=\"trainees\", data = trainee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainees are much younger than non-trainees\r\n",
    "\r\n",
    "This leads to confounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_controled_ols = smf.ols(\"earnings ~ trainees + age\", data = trainee).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Intercept     626.902472\ntrainees    -1540.980167\nage           608.997183\ndtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_controled_ols.params   ## Still leads to a net negative effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still leads to a net negative effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance/match the dataset\r\n",
    "\r\n",
    "**SIMPLE MATCHING**: Make the `trainees==0` dataset unique on age and then join it with the `trainees==1` dataset on `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee.query('trainees==0').count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_non_trainees = trainee.query('trainees==0').drop_duplicates(subset=['age'])\r\n",
    "unique_non_trainees.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join this with the trainees==1 data\r\n",
    "matched_trainees = (trainee\r\n",
    ".query(\"trainees == 1\")\r\n",
    ".merge(unique_non_trainees, on = 'age', how='left', suffixes = ('_t_1', '_t_0'))\r\n",
    ".assign(t1_minus_t0 = lambda d: d['earnings_t_1'] - d['earnings_t_0'])\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0</td>\n      <td>43</td>\n      <td>20900</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>0</td>\n      <td>50</td>\n      <td>31000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0</td>\n      <td>30</td>\n      <td>21000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0</td>\n      <td>27</td>\n      <td>9300</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>0</td>\n      <td>54</td>\n      <td>41100</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>0</td>\n      <td>48</td>\n      <td>29800</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>0</td>\n      <td>39</td>\n      <td>42000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0</td>\n      <td>28</td>\n      <td>8800</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0</td>\n      <td>24</td>\n      <td>25500</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0</td>\n      <td>33</td>\n      <td>15500</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>31</td>\n      <td>0</td>\n      <td>26</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>32</td>\n      <td>0</td>\n      <td>31</td>\n      <td>26600</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>34</td>\n      <td>0</td>\n      <td>34</td>\n      <td>24200</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>35</td>\n      <td>0</td>\n      <td>25</td>\n      <td>23300</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>37</td>\n      <td>0</td>\n      <td>29</td>\n      <td>6200</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>38</td>\n      <td>0</td>\n      <td>35</td>\n      <td>30200</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>39</td>\n      <td>0</td>\n      <td>32</td>\n      <td>17800</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>40</td>\n      <td>0</td>\n      <td>23</td>\n      <td>9500</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  trainees  age  earnings\n19    20         0   43     20900\n20    21         0   50     31000\n21    22         0   30     21000\n22    23         0   27      9300\n23    24         0   54     41100\n24    25         0   48     29800\n25    26         0   39     42000\n26    27         0   28      8800\n27    28         0   24     25500\n28    29         0   33     15500\n29    31         0   26       400\n30    32         0   31     26600\n32    34         0   34     24200\n33    35         0   25     23300\n35    37         0   29      6200\n36    38         0   35     30200\n37    39         0   32     17800\n38    40         0   23      9500"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_non_trainees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_t_1</th>\n      <th>trainees_t_1</th>\n      <th>age</th>\n      <th>earnings_t_1</th>\n      <th>unit_t_0</th>\n      <th>trainees_t_0</th>\n      <th>earnings_t_0</th>\n      <th>t1_minus_t0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>27</td>\n      <td>0</td>\n      <td>8800</td>\n      <td>8900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>34</td>\n      <td>0</td>\n      <td>24200</td>\n      <td>-14000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>37</td>\n      <td>0</td>\n      <td>6200</td>\n      <td>8200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>35</td>\n      <td>0</td>\n      <td>23300</td>\n      <td>-2500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>37</td>\n      <td>0</td>\n      <td>6200</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>1</td>\n      <td>23</td>\n      <td>28600</td>\n      <td>40</td>\n      <td>0</td>\n      <td>9500</td>\n      <td>19100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>33</td>\n      <td>21900</td>\n      <td>29</td>\n      <td>0</td>\n      <td>15500</td>\n      <td>6400</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>27</td>\n      <td>28800</td>\n      <td>23</td>\n      <td>0</td>\n      <td>9300</td>\n      <td>19500</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>31</td>\n      <td>20300</td>\n      <td>32</td>\n      <td>0</td>\n      <td>26600</td>\n      <td>-6300</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>26</td>\n      <td>28100</td>\n      <td>31</td>\n      <td>0</td>\n      <td>400</td>\n      <td>27700</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>25</td>\n      <td>9400</td>\n      <td>35</td>\n      <td>0</td>\n      <td>23300</td>\n      <td>-13900</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>27</td>\n      <td>14300</td>\n      <td>23</td>\n      <td>0</td>\n      <td>9300</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>1</td>\n      <td>29</td>\n      <td>12500</td>\n      <td>37</td>\n      <td>0</td>\n      <td>6200</td>\n      <td>6300</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>24</td>\n      <td>19700</td>\n      <td>28</td>\n      <td>0</td>\n      <td>25500</td>\n      <td>-5800</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>25</td>\n      <td>10100</td>\n      <td>35</td>\n      <td>0</td>\n      <td>23300</td>\n      <td>-13200</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>1</td>\n      <td>43</td>\n      <td>10700</td>\n      <td>20</td>\n      <td>0</td>\n      <td>20900</td>\n      <td>-10200</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11500</td>\n      <td>27</td>\n      <td>0</td>\n      <td>8800</td>\n      <td>2700</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>27</td>\n      <td>10700</td>\n      <td>23</td>\n      <td>0</td>\n      <td>9300</td>\n      <td>1400</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>1</td>\n      <td>28</td>\n      <td>16300</td>\n      <td>27</td>\n      <td>0</td>\n      <td>8800</td>\n      <td>7500</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit_t_1  trainees_t_1  age  earnings_t_1  unit_t_0  trainees_t_0  \\\n0          1             1   28         17700        27             0   \n1          2             1   34         10200        34             0   \n2          3             1   29         14400        37             0   \n3          4             1   25         20800        35             0   \n4          5             1   29          6100        37             0   \n5          6             1   23         28600        40             0   \n6          7             1   33         21900        29             0   \n7          8             1   27         28800        23             0   \n8          9             1   31         20300        32             0   \n9         10             1   26         28100        31             0   \n10        11             1   25          9400        35             0   \n11        12             1   27         14300        23             0   \n12        13             1   29         12500        37             0   \n13        14             1   24         19700        28             0   \n14        15             1   25         10100        35             0   \n15        16             1   43         10700        20             0   \n16        17             1   28         11500        27             0   \n17        18             1   27         10700        23             0   \n18        19             1   28         16300        27             0   \n\n    earnings_t_0  t1_minus_t0  \n0           8800         8900  \n1          24200       -14000  \n2           6200         8200  \n3          23300        -2500  \n4           6200         -100  \n5           9500        19100  \n6          15500         6400  \n7           9300        19500  \n8          26600        -6300  \n9            400        27700  \n10         23300       -13900  \n11          9300         5000  \n12          6200         6300  \n13         25500        -5800  \n14         23300       -13200  \n15         20900       -10200  \n16          8800         2700  \n17          9300         1400  \n18          8800         7500  "
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_trainees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2457.8947368421054"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_trainees.t1_minus_t0.mean()   ## This is net positive effect of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The net effect of training after adjusting for age is +2457 (net positive effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Use `age` as the random effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bin the age\r\n",
    "\r\n",
    "trainee_grouped = (trainee\r\n",
    ".assign(age_group = lambda d: pd.cut(d.age, 10, labels=[1,2,3,4,5,6,7,8,9,0]))\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>age_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   unit  trainees  age  earnings age_group\n0     1         1   28     17700         2\n1     2         1   34     10200         4\n2     3         1   29     14400         2\n3     4         1   25     20800         1\n4     5         1   29      6100         2"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_grouped = smf.mixedlm(\"earnings ~ trainees\", data = trainee_grouped, groups=trainee_grouped['age_group']).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Intercept    23496.470540\ntrainees       638.904491\nGroup Var        1.559684\ndtype: float64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_grouped.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does not work\r\n",
    "\r\n",
    "The net effect is positive, but, not the correct value. Probably suffers from some control values having bins that do not exist in treatment set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for `age_group` buckets that exists in treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 4, 1, 3, 7]\nCategories (10, int64): [1 < 2 < 3 < 4 ... 7 < 8 < 9 < 0]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee_grouped.query('trainees==1').age_group.unique()   ## Only 1,2,3,4,7 exists in treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "36"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee_grouped_filtered = trainee_grouped[trainee_grouped.age_group.isin([1, 2, 3, 4, 7])]\r\n",
    "trainee_grouped_filtered.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_grouped_bucketed = smf.mixedlm(\"earnings ~ trainees\", data = trainee_grouped_filtered, groups=trainee_grouped_filtered['age_group']).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Intercept    17019.767949\ntrainees       670.599284\nGroup Var        0.160964\ndtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_grouped_bucketed.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does not Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using logistic regression to balance the covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639952\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logistic_model1 = smf.logit(\"trainees ~ age\", data = trainee).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vals = logistic_model1.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:ylabel='Density'>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(x = predicted_vals, hue= trainee.trainees, clip = [0.0, 1.0])\r\n",
    "sns.rugplot(x = predicted_vals,  hue= trainee.trainees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can take the range between 0.2 till 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainee_proScores = trainee\r\n",
    "trainee_proScores['proScore'] = logistic_model1.predict()\r\n",
    "trainee_proScores = trainee_proScores.query(\"proScore >= 0.2 and proScore <= 0.65\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "33"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainee_proScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>proScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>0.534316</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>0.383166</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>0.508802</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>0.609279</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>0.508802</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   unit  trainees  age  earnings  proScore\n0     1         1   28     17700  0.534316\n1     2         1   34     10200  0.383166\n2     3         1   29     14400  0.508802\n3     4         1   25     20800  0.609279\n4     5         1   29      6100  0.508802"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee_proScores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match based on proScores\r\n",
    "\r\n",
    "Using the sklearn `KNeighborsRegressor` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model for the untreated units and fit treated units to get their neighboring untreated units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated = trainee_proScores.query(\"trainees==0\")\r\n",
    "treated = trainee_proScores.query(\"trainees==1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['age']\r\n",
    "y = 'earnings'\r\n",
    "D = 'trainees'\r\n",
    "ps = ['proScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model for untreated units based on AGE\r\n",
    "model_t0 = KNeighborsRegressor(n_neighbors=1).fit(untreated[X], untreated[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = treated.assign(neighbor_pred = model_t0.predict(treated[X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>proScore</th>\n      <th>neighbor_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>0.383166</td>\n      <td>24200.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>33</td>\n      <td>21900</td>\n      <td>0.407607</td>\n      <td>15500.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>27</td>\n      <td>28800</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>31</td>\n      <td>20300</td>\n      <td>0.457769</td>\n      <td>26600.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>26</td>\n      <td>28100</td>\n      <td>0.584680</td>\n      <td>400.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>25</td>\n      <td>9400</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>27</td>\n      <td>14300</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>1</td>\n      <td>29</td>\n      <td>12500</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>24</td>\n      <td>19700</td>\n      <td>0.633336</td>\n      <td>25500.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>25</td>\n      <td>10100</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11500</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>27</td>\n      <td>10700</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>1</td>\n      <td>28</td>\n      <td>16300</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  trainees  age  earnings  proScore  neighbor_pred\n0      1         1   28     17700  0.534316         8800.0\n1      2         1   34     10200  0.383166        24200.0\n2      3         1   29     14400  0.508802         6200.0\n3      4         1   25     20800  0.609279        23300.0\n4      5         1   29      6100  0.508802         6200.0\n6      7         1   33     21900  0.407607        15500.0\n7      8         1   27     28800  0.559651         9300.0\n8      9         1   31     20300  0.457769        26600.0\n9     10         1   26     28100  0.584680          400.0\n10    11         1   25      9400  0.609279        23300.0\n11    12         1   27     14300  0.559651         9300.0\n12    13         1   29     12500  0.508802         6200.0\n13    14         1   24     19700  0.633336        25500.0\n14    15         1   25     10100  0.609279        23300.0\n16    17         1   28     11500  0.534316         8800.0\n17    18         1   27     10700  0.559651         9300.0\n18    19         1   28     16300  0.534316         8800.0"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_t_1</th>\n      <th>trainees_t_1</th>\n      <th>age</th>\n      <th>earnings_t_1</th>\n      <th>unit_t_0</th>\n      <th>trainees_t_0</th>\n      <th>earnings_t_0</th>\n      <th>t1_minus_t0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>27</td>\n      <td>0</td>\n      <td>8800</td>\n      <td>8900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>34</td>\n      <td>0</td>\n      <td>24200</td>\n      <td>-14000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>37</td>\n      <td>0</td>\n      <td>6200</td>\n      <td>8200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>35</td>\n      <td>0</td>\n      <td>23300</td>\n      <td>-2500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>37</td>\n      <td>0</td>\n      <td>6200</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>1</td>\n      <td>23</td>\n      <td>28600</td>\n      <td>40</td>\n      <td>0</td>\n      <td>9500</td>\n      <td>19100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>33</td>\n      <td>21900</td>\n      <td>29</td>\n      <td>0</td>\n      <td>15500</td>\n      <td>6400</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>27</td>\n      <td>28800</td>\n      <td>23</td>\n      <td>0</td>\n      <td>9300</td>\n      <td>19500</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>31</td>\n      <td>20300</td>\n      <td>32</td>\n      <td>0</td>\n      <td>26600</td>\n      <td>-6300</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>26</td>\n      <td>28100</td>\n      <td>31</td>\n      <td>0</td>\n      <td>400</td>\n      <td>27700</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>25</td>\n      <td>9400</td>\n      <td>35</td>\n      <td>0</td>\n      <td>23300</td>\n      <td>-13900</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>27</td>\n      <td>14300</td>\n      <td>23</td>\n      <td>0</td>\n      <td>9300</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>1</td>\n      <td>29</td>\n      <td>12500</td>\n      <td>37</td>\n      <td>0</td>\n      <td>6200</td>\n      <td>6300</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>24</td>\n      <td>19700</td>\n      <td>28</td>\n      <td>0</td>\n      <td>25500</td>\n      <td>-5800</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>25</td>\n      <td>10100</td>\n      <td>35</td>\n      <td>0</td>\n      <td>23300</td>\n      <td>-13200</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>1</td>\n      <td>43</td>\n      <td>10700</td>\n      <td>20</td>\n      <td>0</td>\n      <td>20900</td>\n      <td>-10200</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11500</td>\n      <td>27</td>\n      <td>0</td>\n      <td>8800</td>\n      <td>2700</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>27</td>\n      <td>10700</td>\n      <td>23</td>\n      <td>0</td>\n      <td>9300</td>\n      <td>1400</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>1</td>\n      <td>28</td>\n      <td>16300</td>\n      <td>27</td>\n      <td>0</td>\n      <td>8800</td>\n      <td>7500</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit_t_1  trainees_t_1  age  earnings_t_1  unit_t_0  trainees_t_0  \\\n0          1             1   28         17700        27             0   \n1          2             1   34         10200        34             0   \n2          3             1   29         14400        37             0   \n3          4             1   25         20800        35             0   \n4          5             1   29          6100        37             0   \n5          6             1   23         28600        40             0   \n6          7             1   33         21900        29             0   \n7          8             1   27         28800        23             0   \n8          9             1   31         20300        32             0   \n9         10             1   26         28100        31             0   \n10        11             1   25          9400        35             0   \n11        12             1   27         14300        23             0   \n12        13             1   29         12500        37             0   \n13        14             1   24         19700        28             0   \n14        15             1   25         10100        35             0   \n15        16             1   43         10700        20             0   \n16        17             1   28         11500        27             0   \n17        18             1   27         10700        23             0   \n18        19             1   28         16300        27             0   \n\n    earnings_t_0  t1_minus_t0  \n0           8800         8900  \n1          24200       -14000  \n2           6200         8200  \n3          23300        -2500  \n4           6200         -100  \n5           9500        19100  \n6          15500         6400  \n7           9300        19500  \n8          26600        -6300  \n9            400        27700  \n10         23300       -13900  \n11          9300         5000  \n12          6200         6300  \n13         25500        -5800  \n14         23300       -13200  \n15         20900       -10200  \n16          8800         2700  \n17          9300         1400  \n18          8800         7500  "
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This should be the same as unique\r\n",
    "matched_trainees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsRegressor in module sklearn.neighbors._regression:\n",
      "\n",
      "class KNeighborsRegressor(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.RegressorMixin, sklearn.neighbors._base.NeighborsBase)\n",
      " |  KNeighborsRegressor(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |  \n",
      " |  Regression based on k-nearest neighbors.\n",
      " |  \n",
      " |  The target is predicted by local interpolation of the targets\n",
      " |  associated of the nearest neighbors in the training set.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <regression>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.9\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, default=5\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
      " |      Weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |      Uniform weights are used by default.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, default=30\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : int, default=2\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : str or callable, default='minkowski'\n",
      " |      The distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. See the documentation of :class:`DistanceMetric` for a\n",
      " |      list of available metrics.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square during fit. X may be a :term:`sparse graph`,\n",
      " |      in which case only \"nonzero\" elements may be considered neighbors.\n",
      " |  \n",
      " |  metric_params : dict, default=None\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  effective_metric_ : str or callable\n",
      " |      The distance metric to use. It will be same as the `metric` parameter\n",
      " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      " |      'minkowski' and `p` parameter set to 2.\n",
      " |  \n",
      " |  effective_metric_params_ : dict\n",
      " |      Additional keyword arguments for the metric function. For most metrics\n",
      " |      will be same with `metric_params` parameter, but may also contain the\n",
      " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
      " |      'minkowski'.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_fit_ : int\n",
      " |      Number of samples in the fitted data.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  NearestNeighbors : Unsupervised learner for implementing neighbor searches.\n",
      " |  RadiusNeighborsRegressor : Regression based on neighbors within a fixed radius.\n",
      " |  KNeighborsClassifier : Classifier implementing the k-nearest neighbors vote.\n",
      " |  RadiusNeighborsClassifier : Classifier implementing\n",
      " |      a vote among neighbors within a given radius.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances but\n",
      " |     different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsRegressor\n",
      " |  >>> neigh = KNeighborsRegressor(n_neighbors=2)\n",
      " |  >>> neigh.fit(X, y)\n",
      " |  KNeighborsRegressor(...)\n",
      " |  >>> print(neigh.predict([[1.5]]))\n",
      " |  [0.5]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsRegressor\n",
      " |      sklearn.neighbors._base.KNeighborsMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.neighbors._base.NeighborsBase\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the k-nearest neighbors regressor from the training dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : KNeighborsRegressor\n",
      " |          The fitted k-nearest neighbors regressor.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the target for the provided data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs), dtype=int\n",
      " |          Target values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Find the K-neighbors of a point.\n",
      " |      \n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors required for each sample. The default is the\n",
      " |          value passed to the constructor.\n",
      " |      \n",
      " |      return_distance : bool, default=True\n",
      " |          Whether or not to return the distances.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True.\n",
      " |      \n",
      " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NearestNeighbors\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples)\n",
      " |      NearestNeighbors(n_neighbors=1)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False)\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |          For ``metric='precomputed'`` the shape should be\n",
      " |          (n_queries, n_indexed). Otherwise the shape should be\n",
      " |          (n_queries, n_features).\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors for each sample. The default is the value\n",
      " |          passed to the constructor.\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are distances between points, type of distance\n",
      " |          depends on the selected metric parameter in\n",
      " |          NearestNeighbors class.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
      " |          `n_samples_fit` is the number of samples in the fitted data.\n",
      " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
      " |          The matrix is of CSR format.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
      " |          of Neighbors for points in X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X)\n",
      " |      NearestNeighbors(n_neighbors=2)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KNeighborsRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model for untreated units based on proScore\r\n",
    "model_t0_ps = KNeighborsRegressor(n_neighbors=1).fit(untreated[ps], untreated[y])\r\n",
    "model_t1_ps = KNeighborsRegressor(n_neighbors=1).fit(treated[ps], treated[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = treated.assign(neighbor_pred_ps = model_t0_ps.predict(treated[ps]))\r\n",
    "untreated = untreated.assign(neighbor_pred_ps = model_t1_ps.predict(untreated[ps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_neighbors = pd.concat([treated, untreated], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>proScore</th>\n      <th>neighbor_pred</th>\n      <th>neighbor_pred_ps</th>\n      <th>t1_minus_t0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>-8900.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>0.383166</td>\n      <td>24200.0</td>\n      <td>24200.0</td>\n      <td>14000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>-8200.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>2500.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>33</td>\n      <td>21900</td>\n      <td>0.407607</td>\n      <td>15500.0</td>\n      <td>15500.0</td>\n      <td>-6400.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>27</td>\n      <td>28800</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>-19500.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>31</td>\n      <td>20300</td>\n      <td>0.457769</td>\n      <td>26600.0</td>\n      <td>26600.0</td>\n      <td>6300.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>26</td>\n      <td>28100</td>\n      <td>0.584680</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>-27700.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>25</td>\n      <td>9400</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>13900.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>27</td>\n      <td>14300</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>-5000.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>1</td>\n      <td>29</td>\n      <td>12500</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>-6300.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>24</td>\n      <td>19700</td>\n      <td>0.633336</td>\n      <td>25500.0</td>\n      <td>25500.0</td>\n      <td>5800.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>25</td>\n      <td>10100</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>13200.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11500</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>-2700.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>27</td>\n      <td>10700</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>-1400.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>1</td>\n      <td>28</td>\n      <td>16300</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>-7500.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0</td>\n      <td>30</td>\n      <td>21000</td>\n      <td>0.483242</td>\n      <td>NaN</td>\n      <td>20300.0</td>\n      <td>-700.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0</td>\n      <td>27</td>\n      <td>9300</td>\n      <td>0.559651</td>\n      <td>NaN</td>\n      <td>28800.0</td>\n      <td>19500.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>0</td>\n      <td>39</td>\n      <td>42000</td>\n      <td>0.271411</td>\n      <td>NaN</td>\n      <td>10200.0</td>\n      <td>-31800.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0</td>\n      <td>28</td>\n      <td>8800</td>\n      <td>0.534316</td>\n      <td>NaN</td>\n      <td>17700.0</td>\n      <td>8900.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0</td>\n      <td>24</td>\n      <td>25500</td>\n      <td>0.633336</td>\n      <td>NaN</td>\n      <td>19700.0</td>\n      <td>-5800.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0</td>\n      <td>33</td>\n      <td>15500</td>\n      <td>0.407607</td>\n      <td>NaN</td>\n      <td>21900.0</td>\n      <td>6400.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>31</td>\n      <td>0</td>\n      <td>26</td>\n      <td>400</td>\n      <td>0.584680</td>\n      <td>NaN</td>\n      <td>28100.0</td>\n      <td>27700.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>32</td>\n      <td>0</td>\n      <td>31</td>\n      <td>26600</td>\n      <td>0.457769</td>\n      <td>NaN</td>\n      <td>20300.0</td>\n      <td>-6300.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>33</td>\n      <td>0</td>\n      <td>26</td>\n      <td>16500</td>\n      <td>0.584680</td>\n      <td>NaN</td>\n      <td>28100.0</td>\n      <td>11600.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>34</td>\n      <td>0</td>\n      <td>34</td>\n      <td>24200</td>\n      <td>0.383166</td>\n      <td>NaN</td>\n      <td>10200.0</td>\n      <td>-14000.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>35</td>\n      <td>0</td>\n      <td>25</td>\n      <td>23300</td>\n      <td>0.609279</td>\n      <td>NaN</td>\n      <td>20800.0</td>\n      <td>-2500.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>36</td>\n      <td>0</td>\n      <td>24</td>\n      <td>9700</td>\n      <td>0.633336</td>\n      <td>NaN</td>\n      <td>19700.0</td>\n      <td>10000.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>37</td>\n      <td>0</td>\n      <td>29</td>\n      <td>6200</td>\n      <td>0.508802</td>\n      <td>NaN</td>\n      <td>14400.0</td>\n      <td>8200.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>38</td>\n      <td>0</td>\n      <td>35</td>\n      <td>30200</td>\n      <td>0.359300</td>\n      <td>NaN</td>\n      <td>10200.0</td>\n      <td>-20000.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>39</td>\n      <td>0</td>\n      <td>32</td>\n      <td>17800</td>\n      <td>0.432515</td>\n      <td>NaN</td>\n      <td>21900.0</td>\n      <td>4100.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>41</td>\n      <td>0</td>\n      <td>32</td>\n      <td>25900</td>\n      <td>0.432515</td>\n      <td>NaN</td>\n      <td>21900.0</td>\n      <td>-4000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  trainees  age  earnings  proScore  neighbor_pred  neighbor_pred_ps  \\\n0      1         1   28     17700  0.534316         8800.0            8800.0   \n1      2         1   34     10200  0.383166        24200.0           24200.0   \n2      3         1   29     14400  0.508802         6200.0            6200.0   \n3      4         1   25     20800  0.609279        23300.0           23300.0   \n4      5         1   29      6100  0.508802         6200.0            6200.0   \n6      7         1   33     21900  0.407607        15500.0           15500.0   \n7      8         1   27     28800  0.559651         9300.0            9300.0   \n8      9         1   31     20300  0.457769        26600.0           26600.0   \n9     10         1   26     28100  0.584680          400.0             400.0   \n10    11         1   25      9400  0.609279        23300.0           23300.0   \n11    12         1   27     14300  0.559651         9300.0            9300.0   \n12    13         1   29     12500  0.508802         6200.0            6200.0   \n13    14         1   24     19700  0.633336        25500.0           25500.0   \n14    15         1   25     10100  0.609279        23300.0           23300.0   \n16    17         1   28     11500  0.534316         8800.0            8800.0   \n17    18         1   27     10700  0.559651         9300.0            9300.0   \n18    19         1   28     16300  0.534316         8800.0            8800.0   \n21    22         0   30     21000  0.483242            NaN           20300.0   \n22    23         0   27      9300  0.559651            NaN           28800.0   \n25    26         0   39     42000  0.271411            NaN           10200.0   \n26    27         0   28      8800  0.534316            NaN           17700.0   \n27    28         0   24     25500  0.633336            NaN           19700.0   \n28    29         0   33     15500  0.407607            NaN           21900.0   \n29    31         0   26       400  0.584680            NaN           28100.0   \n30    32         0   31     26600  0.457769            NaN           20300.0   \n31    33         0   26     16500  0.584680            NaN           28100.0   \n32    34         0   34     24200  0.383166            NaN           10200.0   \n33    35         0   25     23300  0.609279            NaN           20800.0   \n34    36         0   24      9700  0.633336            NaN           19700.0   \n35    37         0   29      6200  0.508802            NaN           14400.0   \n36    38         0   35     30200  0.359300            NaN           10200.0   \n37    39         0   32     17800  0.432515            NaN           21900.0   \n39    41         0   32     25900  0.432515            NaN           21900.0   \n\n    t1_minus_t0  \n0       -8900.0  \n1       14000.0  \n2       -8200.0  \n3        2500.0  \n4         100.0  \n6       -6400.0  \n7      -19500.0  \n8        6300.0  \n9      -27700.0  \n10      13900.0  \n11      -5000.0  \n12      -6300.0  \n13       5800.0  \n14      13200.0  \n16      -2700.0  \n17      -1400.0  \n18      -7500.0  \n21       -700.0  \n22      19500.0  \n25     -31800.0  \n26       8900.0  \n27      -5800.0  \n28       6400.0  \n29      27700.0  \n30      -6300.0  \n31      11600.0  \n32     -14000.0  \n33      -2500.0  \n34      10000.0  \n35       8200.0  \n36     -20000.0  \n37       4100.0  \n39      -4000.0  "
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_neighbors = complete_neighbors.assign(t1_minus_t0 = lambda d: d.neighbor_pred_ps - d.earnings)\r\n",
    "complete_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-803.030303030303"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_neighbors.t1_minus_t0.mean()  ## sees problem due to diff no.s of age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These values are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual diff computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{ATE} = \\frac{1}{N} \\sum^N_{i=0} (2T_i - 1)\\big(Y_i - Y_{jm}(i)\\big)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average treatment effect ATE = 1487.878787878788\n"
     ]
    }
   ],
   "source": [
    "ATE = np.mean((2* complete_neighbors['trainees'] - 1) * (complete_neighbors['earnings'] - complete_neighbors['neighbor_pred_ps']))\r\n",
    "print(f\" Average treatment effect ATE = {ATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average treatment effect ATT = 2223.529411764706\n"
     ]
    }
   ],
   "source": [
    "ATT = np.mean((complete_neighbors.query(\"trainees==1\")['earnings'] - complete_neighbors.query(\"trainees==1\")['neighbor_pred_ps']))\r\n",
    "print(f\" Average treatment effect ATT = {ATT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias corrected ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>proScore</th>\n      <th>neighbor_pred_ps</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0</td>\n      <td>30</td>\n      <td>21000</td>\n      <td>0.483242</td>\n      <td>20300.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0</td>\n      <td>27</td>\n      <td>9300</td>\n      <td>0.559651</td>\n      <td>28800.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>0</td>\n      <td>39</td>\n      <td>42000</td>\n      <td>0.271411</td>\n      <td>10200.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0</td>\n      <td>28</td>\n      <td>8800</td>\n      <td>0.534316</td>\n      <td>17700.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0</td>\n      <td>24</td>\n      <td>25500</td>\n      <td>0.633336</td>\n      <td>19700.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0</td>\n      <td>33</td>\n      <td>15500</td>\n      <td>0.407607</td>\n      <td>21900.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>31</td>\n      <td>0</td>\n      <td>26</td>\n      <td>400</td>\n      <td>0.584680</td>\n      <td>28100.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>32</td>\n      <td>0</td>\n      <td>31</td>\n      <td>26600</td>\n      <td>0.457769</td>\n      <td>20300.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>33</td>\n      <td>0</td>\n      <td>26</td>\n      <td>16500</td>\n      <td>0.584680</td>\n      <td>28100.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>34</td>\n      <td>0</td>\n      <td>34</td>\n      <td>24200</td>\n      <td>0.383166</td>\n      <td>10200.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>35</td>\n      <td>0</td>\n      <td>25</td>\n      <td>23300</td>\n      <td>0.609279</td>\n      <td>20800.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>36</td>\n      <td>0</td>\n      <td>24</td>\n      <td>9700</td>\n      <td>0.633336</td>\n      <td>19700.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>37</td>\n      <td>0</td>\n      <td>29</td>\n      <td>6200</td>\n      <td>0.508802</td>\n      <td>14400.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>38</td>\n      <td>0</td>\n      <td>35</td>\n      <td>30200</td>\n      <td>0.359300</td>\n      <td>10200.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>39</td>\n      <td>0</td>\n      <td>32</td>\n      <td>17800</td>\n      <td>0.432515</td>\n      <td>21900.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>41</td>\n      <td>0</td>\n      <td>32</td>\n      <td>25900</td>\n      <td>0.432515</td>\n      <td>21900.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  trainees  age  earnings  proScore  neighbor_pred_ps\n21    22         0   30     21000  0.483242           20300.0\n22    23         0   27      9300  0.559651           28800.0\n25    26         0   39     42000  0.271411           10200.0\n26    27         0   28      8800  0.534316           17700.0\n27    28         0   24     25500  0.633336           19700.0\n28    29         0   33     15500  0.407607           21900.0\n29    31         0   26       400  0.584680           28100.0\n30    32         0   31     26600  0.457769           20300.0\n31    33         0   26     16500  0.584680           28100.0\n32    34         0   34     24200  0.383166           10200.0\n33    35         0   25     23300  0.609279           20800.0\n34    36         0   24      9700  0.633336           19700.0\n35    37         0   29      6200  0.508802           14400.0\n36    38         0   35     30200  0.359300           10200.0\n37    39         0   32     17800  0.432515           21900.0\n39    41         0   32     25900  0.432515           21900.0"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untreated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model the untreated and then predict the treated using that model\r\n",
    "t0_model_lr = LinearRegression().fit(untreated[X], untreated[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>proScore</th>\n      <th>neighbor_pred</th>\n      <th>neighbor_pred_ps</th>\n      <th>t1_minus_t0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>8900.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>0.383166</td>\n      <td>24200.0</td>\n      <td>24200.0</td>\n      <td>-14000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>8200.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>-2500.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>-100.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>33</td>\n      <td>21900</td>\n      <td>0.407607</td>\n      <td>15500.0</td>\n      <td>15500.0</td>\n      <td>6400.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>27</td>\n      <td>28800</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>19500.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>31</td>\n      <td>20300</td>\n      <td>0.457769</td>\n      <td>26600.0</td>\n      <td>26600.0</td>\n      <td>-6300.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>26</td>\n      <td>28100</td>\n      <td>0.584680</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>27700.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>25</td>\n      <td>9400</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>-13900.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>27</td>\n      <td>14300</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>5000.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>1</td>\n      <td>29</td>\n      <td>12500</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>6300.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>24</td>\n      <td>19700</td>\n      <td>0.633336</td>\n      <td>25500.0</td>\n      <td>25500.0</td>\n      <td>-5800.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>25</td>\n      <td>10100</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>-13200.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11500</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>2700.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>27</td>\n      <td>10700</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>1400.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>1</td>\n      <td>28</td>\n      <td>16300</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>7500.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  trainees  age  earnings  proScore  neighbor_pred  neighbor_pred_ps  \\\n0      1         1   28     17700  0.534316         8800.0            8800.0   \n1      2         1   34     10200  0.383166        24200.0           24200.0   \n2      3         1   29     14400  0.508802         6200.0            6200.0   \n3      4         1   25     20800  0.609279        23300.0           23300.0   \n4      5         1   29      6100  0.508802         6200.0            6200.0   \n6      7         1   33     21900  0.407607        15500.0           15500.0   \n7      8         1   27     28800  0.559651         9300.0            9300.0   \n8      9         1   31     20300  0.457769        26600.0           26600.0   \n9     10         1   26     28100  0.584680          400.0             400.0   \n10    11         1   25      9400  0.609279        23300.0           23300.0   \n11    12         1   27     14300  0.559651         9300.0            9300.0   \n12    13         1   29     12500  0.508802         6200.0            6200.0   \n13    14         1   24     19700  0.633336        25500.0           25500.0   \n14    15         1   25     10100  0.609279        23300.0           23300.0   \n16    17         1   28     11500  0.534316         8800.0            8800.0   \n17    18         1   27     10700  0.559651         9300.0            9300.0   \n18    19         1   28     16300  0.534316         8800.0            8800.0   \n\n    t1_minus_t0  \n0        8900.0  \n1      -14000.0  \n2        8200.0  \n3       -2500.0  \n4        -100.0  \n6        6400.0  \n7       19500.0  \n8       -6300.0  \n9       27700.0  \n10     -13900.0  \n11       5000.0  \n12       6300.0  \n13      -5800.0  \n14     -13200.0  \n16       2700.0  \n17       1400.0  \n18       7500.0  "
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = (treated\r\n",
    ".assign(t0_model_lr_term = t0_model_lr.predict(treated[X]))\r\n",
    ".assign(bias_term = lambda d: d.t0_model_lr_term - d.neighbor_pred)\r\n",
    ".assign(bias_corrected_term = lambda d: (d.earnings - d.neighbor_pred) - d.bias_term)\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>trainees</th>\n      <th>age</th>\n      <th>earnings</th>\n      <th>proScore</th>\n      <th>neighbor_pred</th>\n      <th>neighbor_pred_ps</th>\n      <th>t1_minus_t0</th>\n      <th>t0_model_lr_term</th>\n      <th>bias_term</th>\n      <th>bias_corrected_term</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>28</td>\n      <td>17700</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>8900.0</td>\n      <td>16329.247169</td>\n      <td>7529.247169</td>\n      <td>1370.752831</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>34</td>\n      <td>10200</td>\n      <td>0.383166</td>\n      <td>24200.0</td>\n      <td>24200.0</td>\n      <td>-14000.0</td>\n      <td>25580.812791</td>\n      <td>1380.812791</td>\n      <td>-15380.812791</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>29</td>\n      <td>14400</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>8200.0</td>\n      <td>17871.174772</td>\n      <td>11671.174772</td>\n      <td>-3471.174772</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20800</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>-2500.0</td>\n      <td>11703.464357</td>\n      <td>-11596.535643</td>\n      <td>9096.535643</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n      <td>6100</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>-100.0</td>\n      <td>17871.174772</td>\n      <td>11671.174772</td>\n      <td>-11771.174772</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1</td>\n      <td>33</td>\n      <td>21900</td>\n      <td>0.407607</td>\n      <td>15500.0</td>\n      <td>15500.0</td>\n      <td>6400.0</td>\n      <td>24038.885188</td>\n      <td>8538.885188</td>\n      <td>-2138.885188</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1</td>\n      <td>27</td>\n      <td>28800</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>19500.0</td>\n      <td>14787.319565</td>\n      <td>5487.319565</td>\n      <td>14012.680435</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>31</td>\n      <td>20300</td>\n      <td>0.457769</td>\n      <td>26600.0</td>\n      <td>26600.0</td>\n      <td>-6300.0</td>\n      <td>20955.029980</td>\n      <td>-5644.970020</td>\n      <td>-655.029980</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>26</td>\n      <td>28100</td>\n      <td>0.584680</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>27700.0</td>\n      <td>13245.391961</td>\n      <td>12845.391961</td>\n      <td>14854.608039</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>25</td>\n      <td>9400</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>-13900.0</td>\n      <td>11703.464357</td>\n      <td>-11596.535643</td>\n      <td>-2303.464357</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>27</td>\n      <td>14300</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>5000.0</td>\n      <td>14787.319565</td>\n      <td>5487.319565</td>\n      <td>-487.319565</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>1</td>\n      <td>29</td>\n      <td>12500</td>\n      <td>0.508802</td>\n      <td>6200.0</td>\n      <td>6200.0</td>\n      <td>6300.0</td>\n      <td>17871.174772</td>\n      <td>11671.174772</td>\n      <td>-5371.174772</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>1</td>\n      <td>24</td>\n      <td>19700</td>\n      <td>0.633336</td>\n      <td>25500.0</td>\n      <td>25500.0</td>\n      <td>-5800.0</td>\n      <td>10161.536753</td>\n      <td>-15338.463247</td>\n      <td>9538.463247</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1</td>\n      <td>25</td>\n      <td>10100</td>\n      <td>0.609279</td>\n      <td>23300.0</td>\n      <td>23300.0</td>\n      <td>-13200.0</td>\n      <td>11703.464357</td>\n      <td>-11596.535643</td>\n      <td>-1603.464357</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11500</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>2700.0</td>\n      <td>16329.247169</td>\n      <td>7529.247169</td>\n      <td>-4829.247169</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>27</td>\n      <td>10700</td>\n      <td>0.559651</td>\n      <td>9300.0</td>\n      <td>9300.0</td>\n      <td>1400.0</td>\n      <td>14787.319565</td>\n      <td>5487.319565</td>\n      <td>-4087.319565</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>1</td>\n      <td>28</td>\n      <td>16300</td>\n      <td>0.534316</td>\n      <td>8800.0</td>\n      <td>8800.0</td>\n      <td>7500.0</td>\n      <td>16329.247169</td>\n      <td>7529.247169</td>\n      <td>-29.247169</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  trainees  age  earnings  proScore  neighbor_pred  neighbor_pred_ps  \\\n0      1         1   28     17700  0.534316         8800.0            8800.0   \n1      2         1   34     10200  0.383166        24200.0           24200.0   \n2      3         1   29     14400  0.508802         6200.0            6200.0   \n3      4         1   25     20800  0.609279        23300.0           23300.0   \n4      5         1   29      6100  0.508802         6200.0            6200.0   \n6      7         1   33     21900  0.407607        15500.0           15500.0   \n7      8         1   27     28800  0.559651         9300.0            9300.0   \n8      9         1   31     20300  0.457769        26600.0           26600.0   \n9     10         1   26     28100  0.584680          400.0             400.0   \n10    11         1   25      9400  0.609279        23300.0           23300.0   \n11    12         1   27     14300  0.559651         9300.0            9300.0   \n12    13         1   29     12500  0.508802         6200.0            6200.0   \n13    14         1   24     19700  0.633336        25500.0           25500.0   \n14    15         1   25     10100  0.609279        23300.0           23300.0   \n16    17         1   28     11500  0.534316         8800.0            8800.0   \n17    18         1   27     10700  0.559651         9300.0            9300.0   \n18    19         1   28     16300  0.534316         8800.0            8800.0   \n\n    t1_minus_t0  t0_model_lr_term     bias_term  bias_corrected_term  \n0        8900.0      16329.247169   7529.247169          1370.752831  \n1      -14000.0      25580.812791   1380.812791        -15380.812791  \n2        8200.0      17871.174772  11671.174772         -3471.174772  \n3       -2500.0      11703.464357 -11596.535643          9096.535643  \n4        -100.0      17871.174772  11671.174772        -11771.174772  \n6        6400.0      24038.885188   8538.885188         -2138.885188  \n7       19500.0      14787.319565   5487.319565         14012.680435  \n8       -6300.0      20955.029980  -5644.970020          -655.029980  \n9       27700.0      13245.391961  12845.391961         14854.608039  \n10     -13900.0      11703.464357 -11596.535643         -2303.464357  \n11       5000.0      14787.319565   5487.319565          -487.319565  \n12       6300.0      17871.174772  11671.174772         -5371.174772  \n13      -5800.0      10161.536753 -15338.463247          9538.463247  \n14     -13200.0      11703.464357 -11596.535643         -1603.464357  \n16       2700.0      16329.247169   7529.247169         -4829.247169  \n17       1400.0      14787.319565   5487.319565         -4087.319565  \n18       7500.0      16329.247169   7529.247169           -29.247169  "
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2223.529411764706"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated.t1_minus_t0.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_melted = treated.melt(id_vars=['unit', 'age'], value_vars=['earnings','neighbor_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>age</th>\n      <th>variable</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>28</td>\n      <td>earnings</td>\n      <td>17700.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>34</td>\n      <td>earnings</td>\n      <td>10200.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>29</td>\n      <td>earnings</td>\n      <td>14400.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>25</td>\n      <td>earnings</td>\n      <td>20800.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>29</td>\n      <td>earnings</td>\n      <td>6100.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>33</td>\n      <td>earnings</td>\n      <td>21900.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8</td>\n      <td>27</td>\n      <td>earnings</td>\n      <td>28800.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>9</td>\n      <td>31</td>\n      <td>earnings</td>\n      <td>20300.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>26</td>\n      <td>earnings</td>\n      <td>28100.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>11</td>\n      <td>25</td>\n      <td>earnings</td>\n      <td>9400.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12</td>\n      <td>27</td>\n      <td>earnings</td>\n      <td>14300.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>13</td>\n      <td>29</td>\n      <td>earnings</td>\n      <td>12500.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14</td>\n      <td>24</td>\n      <td>earnings</td>\n      <td>19700.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>15</td>\n      <td>25</td>\n      <td>earnings</td>\n      <td>10100.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>17</td>\n      <td>28</td>\n      <td>earnings</td>\n      <td>11500.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>18</td>\n      <td>27</td>\n      <td>earnings</td>\n      <td>10700.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>19</td>\n      <td>28</td>\n      <td>earnings</td>\n      <td>16300.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>28</td>\n      <td>neighbor_pred</td>\n      <td>8800.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>34</td>\n      <td>neighbor_pred</td>\n      <td>24200.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>3</td>\n      <td>29</td>\n      <td>neighbor_pred</td>\n      <td>6200.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>4</td>\n      <td>25</td>\n      <td>neighbor_pred</td>\n      <td>23300.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>5</td>\n      <td>29</td>\n      <td>neighbor_pred</td>\n      <td>6200.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>7</td>\n      <td>33</td>\n      <td>neighbor_pred</td>\n      <td>15500.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>8</td>\n      <td>27</td>\n      <td>neighbor_pred</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>9</td>\n      <td>31</td>\n      <td>neighbor_pred</td>\n      <td>26600.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10</td>\n      <td>26</td>\n      <td>neighbor_pred</td>\n      <td>400.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>11</td>\n      <td>25</td>\n      <td>neighbor_pred</td>\n      <td>23300.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>12</td>\n      <td>27</td>\n      <td>neighbor_pred</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>13</td>\n      <td>29</td>\n      <td>neighbor_pred</td>\n      <td>6200.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>14</td>\n      <td>24</td>\n      <td>neighbor_pred</td>\n      <td>25500.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>15</td>\n      <td>25</td>\n      <td>neighbor_pred</td>\n      <td>23300.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>17</td>\n      <td>28</td>\n      <td>neighbor_pred</td>\n      <td>8800.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>18</td>\n      <td>27</td>\n      <td>neighbor_pred</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>19</td>\n      <td>28</td>\n      <td>neighbor_pred</td>\n      <td>8800.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    unit  age       variable    value\n0      1   28       earnings  17700.0\n1      2   34       earnings  10200.0\n2      3   29       earnings  14400.0\n3      4   25       earnings  20800.0\n4      5   29       earnings   6100.0\n5      7   33       earnings  21900.0\n6      8   27       earnings  28800.0\n7      9   31       earnings  20300.0\n8     10   26       earnings  28100.0\n9     11   25       earnings   9400.0\n10    12   27       earnings  14300.0\n11    13   29       earnings  12500.0\n12    14   24       earnings  19700.0\n13    15   25       earnings  10100.0\n14    17   28       earnings  11500.0\n15    18   27       earnings  10700.0\n16    19   28       earnings  16300.0\n17     1   28  neighbor_pred   8800.0\n18     2   34  neighbor_pred  24200.0\n19     3   29  neighbor_pred   6200.0\n20     4   25  neighbor_pred  23300.0\n21     5   29  neighbor_pred   6200.0\n22     7   33  neighbor_pred  15500.0\n23     8   27  neighbor_pred   9300.0\n24     9   31  neighbor_pred  26600.0\n25    10   26  neighbor_pred    400.0\n26    11   25  neighbor_pred  23300.0\n27    12   27  neighbor_pred   9300.0\n28    13   29  neighbor_pred   6200.0\n29    14   24  neighbor_pred  25500.0\n30    15   25  neighbor_pred  23300.0\n31    17   28  neighbor_pred   8800.0\n32    18   27  neighbor_pred   9300.0\n33    19   28  neighbor_pred   8800.0"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = smf.ols(\"value ~ variable + age\", data = treated_melted).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>value</td>      <th>  R-squared:         </th> <td>   0.025</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.038</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.3937</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Tue, 29 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.678</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>18:58:05</td>     <th>  Log-Likelihood:    </th> <td> -351.01</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    34</td>      <th>  AIC:               </th> <td>   708.0</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    31</td>      <th>  BIC:               </th> <td>   712.6</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>                 <td> 1.997e+04</td> <td> 1.39e+04</td> <td>    1.439</td> <td> 0.160</td> <td>-8328.403</td> <td> 4.83e+04</td>\n</tr>\n<tr>\n  <th>variable[T.neighbor_pred]</th> <td>-2223.5294</td> <td> 2646.500</td> <td>   -0.840</td> <td> 0.407</td> <td>-7621.102</td> <td> 3174.043</td>\n</tr>\n<tr>\n  <th>age</th>                       <td> -140.4306</td> <td>  492.060</td> <td>   -0.285</td> <td> 0.777</td> <td>-1143.993</td> <td>  863.131</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 5.056</td> <th>  Durbin-Watson:     </th> <td>   2.656</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.080</td> <th>  Jarque-Bera (JB):  </th> <td>   2.411</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.368</td> <th>  Prob(JB):          </th> <td>   0.299</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 1.923</td> <th>  Cond. No.          </th> <td>    295.</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  value   R-squared:                       0.025\nModel:                            OLS   Adj. R-squared:                 -0.038\nMethod:                 Least Squares   F-statistic:                    0.3937\nDate:                Tue, 29 Nov 2022   Prob (F-statistic):              0.678\nTime:                        18:58:05   Log-Likelihood:                -351.01\nNo. Observations:                  34   AIC:                             708.0\nDf Residuals:                      31   BIC:                             712.6\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nIntercept                  1.997e+04   1.39e+04      1.439      0.160   -8328.403    4.83e+04\nvariable[T.neighbor_pred] -2223.5294   2646.500     -0.840      0.407   -7621.102    3174.043\nage                        -140.4306    492.060     -0.285      0.777   -1143.993     863.131\n==============================================================================\nOmnibus:                        5.056   Durbin-Watson:                   2.656\nProb(Omnibus):                  0.080   Jarque-Bera (JB):                2.411\nSkew:                           0.368   Prob(JB):                        0.299\nKurtosis:                       1.923   Cond. No.                         295.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\""
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-191.48672127078746"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated.bias_corrected_term.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalinference import CausalModel\r\n",
    "\r\n",
    "cm = CausalModel(\r\n",
    "    Y=trainee[\"earnings\"].values, \r\n",
    "    D=trainee[\"trainees\"].values, \r\n",
    "    X=trainee[[\"age\"]].values\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usbahadura\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\causalinference\\estimators\\matching.py:100: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  return np.linalg.lstsq(X, Y)[0][1:]  # don't need intercept coef\n"
     ]
    }
   ],
   "source": [
    "cm.est_via_matching(matches=1, bias_adj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treatment Effect Estimates: Matching\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE  -1101.446   4815.098     -0.229      0.819 -10539.039   8336.147\n",
      "           ATC  -4314.660   4889.464     -0.882      0.378 -13898.009   5268.689\n",
      "           ATT   2450.000   5892.248      0.416      0.678  -9098.806  13998.806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "name": "python3913jvsc74a57bd0b01b1b95d060c09bad5911d0164d6bd1a74fc453030f41a91b1bfed8259492f7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "b01b1b95d060c09bad5911d0164d6bd1a74fc453030f41a91b1bfed8259492f7"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}